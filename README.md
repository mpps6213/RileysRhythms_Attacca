# Rileyâ€™s Rhythms â€” Emotion-Driven Music Experience

**Rileyâ€™s Rhythms** is an AI-powered interactive web application that listens to a userâ€™s voice, understands their emotional state, and recommends music or videos that match their current mood â€” inspired by Disneyâ€™s famous movie: *Inside Out*.

Designed for self emotional wellness, Rileyâ€™s Rhythms blends **speech recognition**, **natural language processing**, and **emotion-aware UI design** to create a personalized, immersive experience.

â€” Key Features
 Real-time Voice Input
 Captures live speech through the userâ€™s microphone.


Emotion Detection
 Uses a transformer-based NLP model to classify emotions including:


Joy


Sadness


Anger


Fear


Surprise


Disgust


Neutral


 Dynamic Emotion-Based UI
 The interface dynamically adapts its:


Color theme


Emotion character visuals


Mood indicators
 based on the detected emotion.


 Personalized Media Recommendations


User-selected music genre support, including:
 Pop, Rock, Hip-Hop, R&B, EDM, Dance, Jazz, Classical, K-Pop, Lofi, Indie, Metal, Country, Blues, Reggae, Punk


Spotify mode: Emotion-aware music recommendations tailored to both mood and genre


YouTube mode: Mood- and genre-based music video search links
---

## Tech Stack
UI Framework: Streamlit


Real-Time Speech Recognition: Vosk


Emotion Analysis (NLP): Hugging Face Transformers


Microphone Audio Input: SoundDevice


Music Recommendation Integration: Spotipy (Spotify Web API)


Video Discovery: YouTube Search


Local Asset Handling: Base64 Encoding


Programming Language: Python 3
---

##  Project Structure

ATTACCA_FINAL/
â”‚
â”œâ”€â”€ app.py                  # Main Streamlit UI & application logic
â”œâ”€â”€ requirements.txt        # Python dependencies (Streamlit, Vosk, Transformers, etc.)
â”œâ”€â”€ README.md               # Project documentation
â”‚
â”œâ”€â”€ models/                 # Speech & NLP models (Vosk acoustic model)
â”‚   â””â”€â”€ vosk-model-en-us-0.22/
â”‚
â”œâ”€â”€ images/                 # Emotion character assets (UI visuals)
â”‚   â”œâ”€â”€ joy.png
â”‚   â”œâ”€â”€ sadness.png
â”‚   â”œâ”€â”€ anger.png
â”‚   â”œâ”€â”€ disgust.png
â”‚   â”œâ”€â”€ fear.png
â”‚   â”œâ”€â”€ neutral.png
â”‚   â””â”€â”€ surprise.png

â”‚
â”œâ”€â”€ RileysRhythms/        â† Virtual Environment (venv)
â”‚   â”œâ”€â”€ Include/
â”‚   â”œâ”€â”€ Lib/
â”‚   â”œâ”€â”€ Scripts/
â”‚   â””â”€â”€ pyvenv.cfg
â”‚
â””â”€â”€ __pycache__/            # Python cache files (auto-generated)

##  How to Run the App (Local)

## 1ï¸. Create & activate a virtual environment
```bash
python -m venv venv .\venv\Scripts\Activate
Windows : .\venv\Scripts\Activate

**## 2. Install dependencies : pip install -r requirements.txt**

**## 3. Run the application : python -m streamlit run app.py**
The website will automatically open in your default web browser.
## Why Rileyâ€™s Rhythms? 
Rileyâ€™s Rhythms explores how emotion-aware AI can:
Enhance personalization


Improve emotional engagement


Create empathetic humanâ€“computer interactions
Potential extensions include:
Mental wellness support tools


Smart entertainment systems


Emotion-adaptive learning platforms
## Team & Hackathon Context
This project was developed for a hackathon to demonstrate:
Applied AI and NLP techniques


Real-time humanâ€“AI interaction


Creative UI/UX driven by emotional intelligence

## AI Assistance & Acknowledgements

This project was developed with the assistance of AI tools for ideation, debugging, and documentation support:
- ChatGPT (OpenAI) â€” used for code explanation, documentation drafting, and design guidance
- Gemini (Google) â€” used for brainstorming and conceptual refinement
- GitHub Copilot â€” used for code suggestions and productivity support

All final implementation decisions, testing, and integration were performed by the project team.


## Notes for Judges 
Speech recognition works offline


No personal data is stored


Designed with clarity, creativity, and technical feasibility in mind


Thank you for exploring Rileyâ€™s Rhythms ğŸ¶ğŸ§ 
